library(PerformanceAnalytics)
library(quantmod)
library(car)
library(FinTS)
nstall.packages("fGarch")
library(fGarch)
library("robustbase", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
getSymbols("TATASTEEL.NS", from="1900-01-01")
rets = na.trim( ROC( Cl( TATASTEEL.NS) ) )
ss = rets["2009/2014"]
ss.v <- as.vector(ss)
 outOfSample = NROW(ss["2014"])
set.seed(123)
   fit = garchFit(~ garch(1, 1), data = ss, trace = FALSE)
   fit
plot(sqrt(252) * fit@sigma.t, type="l")  
predict(fit, n.ahead = 1)
predict(fit, n.ahead = 1, plot=TRUE, crit_val=2)
set.seed(321)
fit2 = garchFit(~ garch(1, 1), data = ss, trace = FALSE, cond.dist="sged")
predict(fit2,n.ahead=1,plot=TRUE)
set.seed(444)
 fit3 = garchFit(~ garch(1, 1), data = ss, trace = FALSE, cond.dist="QMLE")
p<-predict(fit3,n.ahead=1,plot=TRUE,conf=.9,nx=100) 

#if p[1,1] less than p[1,4] or greater than then buy or sell
************
****
getSymbols("TQQQ")
retTQQQ<-na.trim( ROC( Cl(TQQQ) ) )
#retTQQQ<-na.trim(diff(log(TQQQ)))
retTQQQ.v <- as.vector(retTQQQ)
#test<-retTQQQ["2011/2014"]
#train<-retTQQQ["2015"]
****
acf(retTQQQ)
acf(abs(retTQQQ), main="TQQQ abs(Returns)")
acf(retTQQQ^2, main="TQQQ Returns^2")
table.Stats(retTQQQ)
****
set.seed(123)
fit<-garchFit(~ garch(1, 1), data =retTQQQ, trace = FALSE)
summary(fit)
coef(fit)
predict(fit, n.ahead = 1, plot=TRUE, crit_val=2)
plot(sqrt(252) * fit@sigma.t, type="l")
***
install.packages("betategarch")
library("betategarch", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
gest.te <- tegarch.est(retTQQQ)
gest.te
gest.te$par
gfit.te <- tegarch.fit(retTQQQ, gest.te$par)
pp.timeplot(sqrt(252) * gfit.te[, "sigma"] * sd(gfit.te[,"epsilon"]))
Volatility  as estimated by a garch(1,1) model (blue) and by the beta-t EGARCH model (gold). 
****
library("bayesGARCH", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
gbayes <- bayesGARCH(retTQQQ.v)
gbayes
gbayes <- bayesGARCH(retTQQQ.v*100)#in percentage
The bayesGARCH function, though, doesn’t give us an estimate.  It gives us a matrix with columns corresponding to the parameters and rows corresponding to the visits of a Markov Chain Monte Carlo. 
This is, sort of, a sample from the (posterior) distribution of the parameters.We can get a more useful analysis if we impose a constraint on the persistence.  
persistenceCons
function(psi)
    {
      psi[2] + psi[3] < .9986
    }
gbayes.con<- bayesGARCH(retTQQQ.v* 100,control=list(addPriorConditions=persistenceCons))  
gbayesChain<- gbayes.com$chain1[-1:-2500,][c(TRUE,FALSE),]
gbayesHalflife <- log(.5)/log(rowSums(gbayesChain[,c("alpha1", "beta")]))
****
library("tseries", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
gfit.ts <- garch(retTQQQ)
coef(gfit.ts)
plot(sqrt(252) * gfit.ts$fitted.values[, 1], type="l")# plot in-sample volatility estimates
****
library("rugarch")
library("rugarch", lib.loc="~/R/x86_64-pc-linux-gnu-library/3.2")
arch1.spec<-ugarchspec(variance.model = list(garchOrder=c(1,0)),mean.model = list(armaOrder=c(0,0)),fixed.pars=list(mu = 0, omega=0.1, alpha1=0.8))
class(arch1.spec)
set.seed(123)
arch1.sim<-ugarchpath(arch1.spec, n.sim=1000)
class(arch1.sim)
slotNames(arch1.sim)
names(arch1.sim@path)
par(mfrow=c(2,1))
plot(arch1.sim, which=2)
plot(arch1.sim, which=1)
par(mfrow=c(1,1))

par(mfrow=c(3,1))
  acf(arch1.sim@path$seriesSim, main="Returns")
  acf(arch1.sim@path$seriesSim^2, main="Returns^2")
  acf(abs(arch1.sim@path$seriesSim), main="abs(Returns)")
par(mfrow=c(1,1))
# use qqPlot() function from car package
qqPlot(arch1.sim@path$seriesSim, ylab="ARCH(1) Returns")
# Testing for ARCH/GARCH effects in returns
# use Box.test from stats package
Box.test(coredata(retTQQQ^2), type="Ljung-Box", lag = 12)
# use ArchTest() function from FinTS package for Engle's LM test
ArchTest(retTQQQ)
garch11.spec<-ugarchspec(variance.model = list(garchOrder=c(1,1)),mean.model = list(armaOrder=c(0,0)))
TQQQ.garch11.fit<-ugarchfit(spec=garch11.spec, data=retTQQQ,solver.control=list(trace = 1))
class(TQQQ.garch11.fit)
slotNames(TQQQ.garch11.fit)
names(TQQQ.garch11.fit@fit)
names(TQQQ.garch11.fit@model)
# estimated coefficients
coef(TQQQ.garch11.fit)
# unconditional mean in mean equation
uncmean(TQQQ.garch11.fit)
# unconditional variance: omega/(alpha1 + beta1)
uncvariance(TQQQ.garch11.fit)
# persistence: alpha1 + beta1
persistence(TQQQ.garch11.fit)
# half-life:
halflife(TQQQ.garch11.fit)
# residuals: e(t)
plot.ts(residuals(TQQQ.garch11.fit), ylab="e(t)", col="blue")
abline(h=0)
# sigma(t) = conditional volatility
plot.ts(sigma(TQQQ.garch11.fit), ylab="sigma(t)", col="blue")
# illustrate plot method
plot(TQQQ.garch11.fit)
plot(TQQQ.garch11.fit, which=1)
plot(TQQQ.garch11.fit, which="all")
plot(TQQQ.garch11.fit, which=9)
# simulate from fitted model
TQQQ.garch11.sim<-ugarchsim(TQQQ.garch11.fit,n.sim=nrow(retTQQQ),rseed=123,startMethod="unconditional")
class(TQQQ.garch11.sim)
slotNames(TQQQ.garch11.sim)

# plot actual returns and simulated returns
par(mfrow=c(2,1))
plot(retTQQQ, main="Actual TQQQ returns")
plot(as.xts(TQQQ.garch11.sim@simulation$seriesSim,order.by=index(retTQQQ)),main="Simulated GARCH(1,1) Returns")
par(mfrow=c(1,1))
# convergence problems with ARCH(1) fit
arch1.spec<-ugarchspec(variance.model = list(garchOrder=c(1,0)),mean.model = list(armaOrder=c(0,0)))
TQQQ.arch1.fit<-ugarchfit(spec=arch1.spec, data=retTQQQ,solver.control=list(trace = 1))
TQQQ.ret.clean<-Return.clean(retTQQQ, method="boudt")
par(mfrow=c(2,1))
plot(retTQQQ, main="Raw TQQQ Returns", ylab="TQQQ")
plot(TQQQ.ret.clean, main="Cleaned TQQQ Returns", ylab="TQQQ")
par(mfrow=c(1,1))
TQQQ.clean.arch1.fit<-ugarchfit(spec=arch1.spec, data=TQQQ.ret.clean,solver.control=list(trace = 1))
TQQQ.clean.arch1.fit
# model selection on GARCH(p,q) models
arch.order = 1:5
arch.names = paste("arch", arch.order, sep="")
# fit all arch models with p <= 5
arch.list = list()
for (p in arch.order) {
  arch.spec<-ugarchspec(variance.model = list(garchOrder=c(p,0)),mean.model = list(armaOrder=c(0,0)))
  arch.fit<-ugarchfit(spec=arch.spec, data=TQQQ.ret.clean,solver.control=list(trace = 0))
  arch.list[[p]] = arch.fit
}
names(arch.list) = arch.names

# refit GARCH(1,1) to cleaned data
garch11.fit<-ugarchfit(spec=garch11.spec, data=TQQQ.ret.clean,solver.control=list(trace = 0))
arch.list$garch11 = garch11.fit

# extract information criteria for all models
info.mat = sapply(arch.list, infocriteria)
rownames(info.mat) = rownames(infocriteria(arch.list[[1]]))
info.mat
# compare arch(5) to garch(1,1)
par(mfrow=c(2,1))
plot.ts(sigma(garch11.fit), main="GARCH(1,1) conditional vol",ylab="vol", col="blue")
plot.ts(sigma(arch.list$arch5), main="ARCH(5) conditional vol",ylab="vol", col="blue")
par(mfrow=c(1,1))
# forecasting
TQQQ.garch11.fcst<-ugarchforecast(TQQQ.garch11.fit, n.ahead=100)
class(TQQQ.garch11.fcst)
slotNames(TQQQ.garch11.fcst)
names(TQQQ.garch11.fcst@forecast)
TQQQ.garch11.fcst
plot(TQQQ.garch11.fcst)
par(mfrow=c(2,1))
plot(TQQQ.garch11.fcst, which=1)
plot(TQQQ.garch11.fcst, which=3)
par(mfrow=c(1,1))
# forecast from ARCH(5)
TQQQ.arch5.fcst<-ugarchforecast(arch.list$arch5, n.ahead=100)
plot(TQQQ.arch5.fcst)
par(mfrow=c(2,1))
plot(TQQQ.arch5.fcst, which=1)
plot(TQQQ.arch5.fcst, which=3)
par(mfrow=c(1,1))
# compute h-day variance forecast = sum of h-day ahead variance forecasts
TQQQ.fcst.df<-as.data.frame(TQQQ.garch11.fcst)
head(TQQQ.fcst.df)
# h-day return variance forecast = sum of h-day ahead variance forecasts
TQQQ.fcst.var.hDay<-cumsum(TQQQ.fcst.df$sigma^2)
TQQQ.fcst.vol.hDay<-sqrt(TQQQ.fcst.var.hDay)
# plot h-day vol forecasts
fcst.vol.hDay.zoo<-zoo(TQQQ.fcst.vol.hDay, as.Date(rownames(TQQQ.fcst.df)))
chart.TimeSeries(fcst.vol.hDay.zoo, main="GARCH(1,1) Forecast of h-day Return Vol",colorset="blue", ylab="h-day vol forecast")
# computing VaR Forecasts
# h step-ahead conditional normal GARCH(1,1) VaR
VaR.95.garch11<-TQQQ.fcst.df$series[1] + TQQQ.fcst.df$sigma[1]*qnorm(0.05)
VaR.95.garch11
# compute 20-day vol forecast from fitted GARCH(1,1)
sigma.20day<-sqrt(sum(TQQQ.fcst.df$sigma[1:20]^2))
VaR.95.garch11.20day<-20*TQQQ.fcst.df$series[1] + sigma.20day*qnorm(0.05)
VaR.95.garch11.20day
# look at example to see how to implement test
plot(TQQQ.garch11.fit, which="2")
# bootstrap forecast densities
TQQQ.garch11.boot<-ugarchboot(TQQQ.garch11.fit, method="Partial",n.ahead=100, n.bootpred=2000)
class(TQQQ.garch11.boot)
TQQQ.garch11.boot
plot(TQQQ.garch11.boot)
# rolling estimation of GARCH(1,1)
TQQQ.garch11.roll = ugarchroll(garch11.spec,retTQQQ, n.ahead=1,forecast.length = 1000,refit.every=20, refit.window="moving")
class(TQQQ.garch11.roll)
plot(TQQQ.garch11.roll)
# VaR plot
plot(TQQQ.garch11.roll, which=4)
# Coef plot`
plot(TQQQ.garch11.roll, which=5)
# show backtesting report
report(TQQQ.garch11.roll, type="VaR")
report(TQQQ.garch11.roll, type="fpm")
###
gspec.ru <- ugarchspec(mean.model=list(armaOrder=c(0,0)),distribution="std")
gfit.ru <- ugarchfit(gspec.ru,retTQQQ)
coef(gfit.ru)
plot(sqrt(252) * gfit.ru@fit$sigma, type='l')
class(gfit.ru)
str(gfit.ru)
coef(gfit.ru)
infocriteria(gfit.ru)
sigma(gfit.ru)
fitted(gfit.ru)
plot(fitted(gfit.ru))
plot(retTQQQ)
sp<-fitted(gfit.ru)-retTQQQ
plot(sp["2015"])
residuals(gfit.ru)
plot(residuals(gfit.ru)["2015-10/2015-11"])
VaR<-quantile(gfit.ru,0.01)#n-sample VaR
VaR<-gfit.ru@fit$sigma*qnorm(0.01)+gfit.ru@fit$fitted.values#n-sample VaR
#FORECASTING
model.ru<-ugarchforecast(gfit.ru, data = NULL, n.ahead =5, n.roll
= 0, out.sample = 0)
plot(model.ru)
slotNames(model.ru)
fitted(model.ru)
plot(model.ru@forecast$seriesFor)
##ROLLING
ug.roll.model<-ugarchspec (
variance.model = list(model = "sGARCH", garchOrder = c(1, 1)),
mean.model = list(armaOrder = c(0, 0)),
distribution.model = "norm")
ug.roll.modelfit<-ugarchfit(ug.roll.model,data=retTQQQ,out.sample=2)
ug.roll.modelfit@model$modeldata$T
ug.roll.modelfor<-ugarchforecast(ug.roll.modelfit, data = NULL, n.ahead = 1, n.roll= 2, out.sample = 2)
sigma(ug.roll.modelfor)
fitted(ug.roll.modelfor)
mu<-coef(ug.roll.modelfit)["mu"]
VaR<-quantile(ug.roll.modelfor,0.05)
## ROLLING WITH training data set


http://statistics.unl.edu/faculty/bilder/ts/r/garch_docum_example.r
http://finzi.psych.upenn.edu/library/fGarch/html/methods-predict.html
http://www.r-bloggers.com/a-practical-introduction-to-garch-modeling/
http://www.r-bloggers.com/variability-of-garch-predictions/
http://www.stat.nthu.edu.tw/~njhsu/Nonlinear%20Time%20Series/R%20functions%20for%20GARCH%20modeling.pdf
http://yunus.hacettepe.edu.tr/~iozkan/eco665/archgarch.html
http://faculty.washington.edu/ezivot/econ589/ch18-garch.pdf
http://statistics.unl.edu/faculty/bilder/ts/r/garch_docum_example.r
https://systematicinvestor.wordpress.com/2012/01/06/trading-using-garch-volatility-forecast/
https://www.quantstart.com/articles/ARIMA-GARCH-Trading-Strategy-on-the-SP500-Stock-Market-Index-Using-R
http://www.personal.psu.edu/asb17/old/sta4853/files/sta4853-28print.pdf
http://arxiv.org/pdf/1410.8504.pdf
http://eranraviv.com/volatility-forecast-evaluation-in-r/
http://maths-people.anu.edu.au/~johnm/courses/r/ASC2008/pdf/Rtimeseries-ohp.pdf
http://www.stat.ncu.edu.tw/teacher/wenteng/2010%20fall%20teaching/final%20project/Wei-Chih%20Chuang/garch.R
http://faculty.washington.edu/ezivot/econ589/econ589univariateGarch.r
http://www.portfolioprobe.com/2012/07/06/a-practical-introduction-to-garch-modeling/
http://www.reginafloresmir.com/statistics/
http://www.stat.pitt.edu/stoffer/tsa2/textRcode.htm
http://www.financialriskforecasting.com/code/3.html
https://gist.github.com/ivannp/5198580
http://people.orie.cornell.edu/davidr/SDAFE2/Rscripts/garch.R

http://www.investopedia.com/stock-analysis/2012/4-ways-to-trade-the-vix-vxx-vxz-tvix-xxv-xiv0321.aspx
http://www.investopedia.com/articles/optioninvestor/03/091003.asp
http://www.investopedia.com/terms/p/putcallratio.asp
http://www.investopedia.com/terms/m/marketsentiment.asp
http://www.sheridanmentoring.com/vix-options-strategies/

googling : vix option strategies





If the volatility clustering is properly explained by the model, then there will be no autocorrelation in the squared standardized residuals.  It is common to do a Ljung-Box test to test for this autocorrelation,on a fit assuming a normal distribution on returns.
Persistence
The persistence of a garch model has to do with how fast large volatilities decay after a shock. For the garch(1,1) model the key statistic is the sum of the two main parameters (alpha1 and beta1, in the notation we are using here).
The sum of alpha1 and beta1 should be less than 1.  If the sum is greater than 1, then the predictions of volatility are explosive — we’re unlikely to believe that.  If the sum is equal to 1, then we have an exponential decay model.
It is possible to express the persistence as a half-life.  The half-life is log(0.5)/log(alpha1 + beta1), where the units will be the frequency of the returns.  When alpha1+beta1 hits 1, the half-life becomes infinite.
Prediction
The persistence of the model is a key driver of the predictions — it determines how fast the predictions go to the unconditional volatility.  If there really is a lot of persistence in the volatility and your model accurately captures the persistence, then you will get good predictions far ahead.

    the volatility at each time point of the prediction period
    the average volatility from the start of the period to each time point in the period (often called the term structure)
For example, the volatility that goes into an option price is the average volatility until expiry, not the volatility on the expiry date.
Simulation
A garch simulation needs:

    a garch model (including the parameter values)
    a volatility state for the model
    a distribution of standardized (variance 1) innovation values

Almost always the volatility state that we want is the state at the end of the data.  That is, now.  We want to use the current state of volatility and peek into the future.

Using the empirical distribution — the standardized residuals from the fitted model — is often the best choice for the innovations.   The assumption of the distribution when fitting the model does have an influence even when using the empirical distribution.

The estimation procedure “tries” to make the residuals conform to the hypothesized distribution.  The standardized residuals from a model assuming a normal distribution will be closer to normally distributed than the residuals from a model on the same data assuming a t distribution.

Simulation is dependent on the estimated parameters, but not as seriously as with prediction.  Model errors compound as we simulate farther into the future, but they compound with a vengeance when we predict far into the future.


