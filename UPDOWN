F1: Vol-Price factor, -ve
F2:Volatility -ve
F3: Technicals
F4: Regression
F5: Descriptive Analysis 
#***
library("quantmod")
library("rpart")
library("rpart.plot")
library("caTools")
library("caret")
library("kernlab")
library("nnet")
library("foreign")
library("ggplot2")
library("reshape2")
library("PerformanceAnalytics")
library("car")
library("FinTS")
library("fGarch")
library("robustbase")
library("MASS")
library("klaR")
library("lubridate")#Makes it easier to work with the dates
library("e1071")
library("parallel")
library("DMwR")
library("randomForest")
library(‘depmixS4’)
library("forecast") 
#***
getSymbols(c("^GSPC",'^NDX','^OEX','^VIX','UWTI','DWTI','SQQQ','TQQQ','XLE','XLF','XLV','XLY','XLI','TLT','SST','EEM','CAD=X'))
***
F1: PRICE-VOLUME convergence or divergence ??
#Price and Volume change
q3<-na.omit(ROC(Cl(NDX)))
q2<-na.omit(Vo(NDX))
q1<-na.omit(Cl(NDX))
q4<-na.omit(ROC(Vo(NDX)))
rolling_quantile_CL<-rollapply(q1,width=50,FUN=function(y) quantile(y,c(0.01,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.99)),by.column = FALSE, align = "right")
rolling_quantile_VO<-rollapply(q2,width=50,FUN=function(y) quantile(y,c(0.01,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.99)),by.column = FALSE, align = "right")
rolling_quantile_CLR<-rollapply(q3,width=50,FUN=function(y) quantile(y,c(0.01,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.99)),by.column = FALSE, align = "right")
rolling_quantile_VOLR<-rollapply(q4,width=50,FUN=function(y) quantile(y,c(0.01,0.05,0.15,0.25,0.35,0.45,0.55,0.65,0.75,0.85,0.95,0.99)),by.column = FALSE, align = "right")
PU<-ifelse(ROC(Cl(NDX))>=0.0258,5,ifelse(ROC(Cl(NDX))>=0.021 & ROC(Cl(NDX))<0.0258,4,ifelse(ROC(Cl(NDX))>=0.012 & ROC(Cl(NDX))<0.021,3,ifelse(ROC(Cl(NDX))>=0.007 & ROC(Cl(NDX))<0.012,2,ifelse(ROC(Cl(NDX))>=0.002 & ROC(Cl(NDX))<0.007,1,0)))))
PD<-ifelse(ROC(Cl(NDX))<=(-0.0335),-5,ifelse(ROC(Cl(NDX))<=(-0.027) & ROC(Cl(NDX))>(-0.0335),-4,ifelse(ROC(Cl(NDX))<=(-0.014) & ROC(Cl(NDX))>(-0.027),-3,ifelse(ROC(Cl(NDX))<=(-0.005) & ROC(Cl(NDX))>(-0.014),-2,ifelse(ROC(Cl(NDX))<=(-0.0012) & ROC(Cl(NDX))>(-0.005),-1,0)))))
PCUD<-ifelse(ROC(Cl(NDX))>0,PU,PD)
VU<-ifelse(ROC(Vo(NDX))>=0.021,5,ifelse(ROC(Cl(NDX))>=0.01 & ROC(Cl(NDX))<0.02,4,ifelse(ROC(Cl(NDX))>=0.004 & ROC(Cl(NDX))<0.0075,2,ifelse(ROC(Cl(NDX))>=0.002 & ROC(Cl(NDX))<0.004,1,0))))
VD<-ifelse(ROC(Cl(NDX))<=(-0.028),-5,ifelse(ROC(Cl(NDX))<=(-0.016) & ROC(Cl(NDX))>(-0.028),-4,ifelse(ROC(Cl(NDX))<=(-0.01) & ROC(Cl(NDX))>(-0.016),-3,ifelse(ROC(Cl(NDX))<=(-0.005) & ROC(Cl(NDX))>(-0.01),-2,ifelse(ROC(Cl(NDX))<=(-0.0015) & ROC(Cl(NDX))>(-0.05),1,0)))))
VCUD<-ifelse(ROC(Cl(NDX))>0,VU,VD)
##Price and Volume
PL<-ifelse(Cl(NDX)>=rolling_quantile_CL$X1. & Cl(NDX)<rolling_quantile_CL$X5.,1,ifelse(Cl(NDX)>rolling_quantile_CL$X5. & Cl(NDX)<rolling_quantile_CL$X15.,2,ifelse(Cl(NDX)>=rolling_quantile_CL$X15. & Cl(NDX)<rolling_quantile_CL$X25.,3,ifelse(Cl(NDX)>=rolling_quantile_CL$X25. & Cl(NDX)<rolling_quantile_CL$X35.,4,ifelse(Cl(NDX)>=rolling_quantile_CL$X35. & Cl(NDX)<rolling_quantile_CL$X45.,5,ifelse(Cl(NDX)>=rolling_quantile_CL$X45. & Cl(NDX)<rolling_quantile_CL$X55.,6,ifelse(Cl(NDX)>=rolling_quantile_CL$X55. & Cl(NDX)<rolling_quantile_CL$X65.,7,ifelse(Cl(NDX)>=rolling_quantile_CL$X65. & Cl(NDX)<rolling_quantile_CL$X75.,8,ifelse(Cl(NDX)>=rolling_quantile_CL$X75. & Cl(NDX)<rolling_quantile_CL$X85.,9,ifelse(Cl(NDX)>=rolling_quantile_CL$X85. & Cl(NDX)<rolling_quantile_CL$X95.,10,ifelse(Cl(NDX)>=rolling_quantile_CL$X95. & Cl(NDX)<rolling_quantile_CL$X99.,11,ifelse(Cl(NDX)>=rolling_quantile_CL$X99.,12,0))))))))))))
VL<-ifelse(Vo(NDX)>=rolling_quantile_VO$X1. & Vo(NDX)<rolling_quantile_VO$X5.,1,ifelse(Vo(NDX)>rolling_quantile_VO$X5. & Vo(NDX)<rolling_quantile_VO$X15.,2,ifelse(Vo(NDX)>=rolling_quantile_VO$X15. & Vo(NDX)<rolling_quantile_VO$X25.,3,ifelse(Vo(NDX)>=rolling_quantile_VO$X25. & Vo(NDX)<rolling_quantile_VO$X35.,4,ifelse(Vo(NDX)>=rolling_quantile_VO$X35. & Vo(NDX)<rolling_quantile_VO$X45.,5,ifelse(Vo(NDX)>=rolling_quantile_VO$X45. & Vo(NDX)<rolling_quantile_VO$X55.,6,ifelse(Vo(NDX)>=rolling_quantile_VO$X55. & Vo(NDX)<rolling_quantile_VO$X65.,7,ifelse(Vo(NDX)>=rolling_quantile_VO$X65. & Vo(NDX)<rolling_quantile_VO$X75.,8,ifelse(Vo(NDX)>=rolling_quantile_VO$X75. & Vo(NDX)<rolling_quantile_VO$X85.,9,ifelse(Vo(NDX)>=rolling_quantile_VO$X85. & Vo(NDX)<rolling_quantile_VO$X95.,10,ifelse(Vo(NDX)>=rolling_quantile_VO$X95. & Vo(NDX)<rolling_quantile_VO$X99.,11,ifelse(Vo(NDX)>=rolling_quantile_VO$X99.,12,0))))))))))))
  #Plot
par(mfrow=c(2,2))
plot(VCUD["2016-1"])
plot(PCUD["2016-1"])
plot(PL["2016-1"])
plot(VL["2016-1"])
#F2:Volatility
chaiVOL<-na.omit(chaikinVolatility(NDX[,2:3]))
atrVOL<-na.omit(ATR(NDX[,2:4])[,2])
vGK <- Cl(volatility(NDX[,1:4], calc="garman"))
stochOsc <- na.omit(stoch(NDX[,2:4]))
stochWPR<- na.omit(WPR(NDX[,2:4]))
q1=Cl(NDX)
rollSD<-rollapply(q1,width=50,FUN=function(y) stdev(y)/mean(y),by.column = FALSE, align = "right")
#plot
par(mfrow=c(2,3))
plot(chaiVOL["2016-01"])#cor(tail(Cl(NDX),10),tail(chaiVOL,10)) is -72%
plot(atrVOL["2016-01"])#cor(tail(Cl(NDX),10),tail(atrVOL,10)) is -71%
plot(vGK["2016-01"])#cor(tail(Cl(NDX),10),tail(vGK,10)) is 99%
plot(tail(stochOsc[,"fastK"], 100), type="l",main="Fast %K and Williams %R", ylab="",ylim=range(cbind(stochOsc, stochWPR), na.rm=TRUE) )
lines(tail(stochWPR, 100), col="blue")
lines(tail(1-stochWPR, 100), col="red", lty="dashed")
plot(rollSD["2016-01"])#cor(tail(Cl(NDX),10),tail(rollSD,10)) -63%
#INDEX RATIO PLOTS
plot(Cl(NDX)/Cl(GSPC))
plot(Cl(NDX)/Cl(OEX))
plot(Cl(GSPC)/Cl(OEX))
plot(Cl(TQQQ)/Cl(SQQQ))
plot(Cl(TLT)/Cl(SST))
plot(Cl(TLT)/Cl(EEM))
#INDEX
plot(Cl(DWTI))
plot(Cl(UWTI))
plot(Cl(TLT))
plot(Cl(`CAD=X`))
*** PRICE GRAPH
CHOC=Cl(NDX)-Op(NDX)
CHC=Cl(NDX)-lag(Cl(NDX))
d1<-diff(Op(NDX))
logd1<-diff(log(Cl(NDX)))
sd1<-diff(sqrt(Cl(NDX)))
doc1<-na.omit(diff(CHOC))
logdoc1<-na.omit(log(CHOC))
sdoc1<-na.omit(diff(sqrt(CHOC)))
par(mfrow=c(3,3))
plot(Cl(NDX)["2016"],type='l',xlab='Time',ylab='Close Prices',main='Daily Close Prices')# only close price
plot(na.omit(CHC)["2016"],type='l',xlab='Time',ylab='Close Price difference from yesterday',main='Daily Close Price difference from yesterday')# Change in a day
plot(d1["2016"],type='l',xlab='Time',ylab='Difference',main='First Degree Differencing on Open Data')
plot(logd1["2016"],type='l',xlab='Time',ylab='Difference',main='First Degree Differencing on Logged close Data')
plot(sd1["2016"],type='l',xlab='Time',ylab='Difference',main='First Degree Differencing on Square-root close Data')
plot(CHOC["2016"],type='l',xlab='Time',ylab='Close Price difference from opening',main='Daily Close Prices difference from opening')# Change in a day
plot(doc1["2016"],type='l',xlab='Time',ylab='Difference',main='First Degree Differencing on CL-OP Data')
plot(logdoc1["2016"],type='l',xlab='Time',ylab='Difference',main='First Degree Differencing on Logged CL-OP Data')
plot(sdoc1["2015/2016"],type='l',xlab='Time',ylab='Difference',main='First Degree Differencing on Square-root CL-OP Data')
#F3#Technical Indicators
RSI5<-RSI(Op(NDX), n= 5)#Calculate a 5-period relative strength index (RSI) off the open price strength index (RSI) off the open price
EMA15<-EMA(Op(NDX),n=15)#Calculate a 5-period exponential moving average (EMA)
EMAcross<- Op(NDX)-EMA15#Let’s explore the difference between the open price and our 5-period EMA
SMA15<-SMA(Op(NDX),n=15)
Trend<-Op(NDX)-SMA15#Our measure of trend: the difference between the open price and the 15-period simple moving average.
MACD<-MACD(Op(NDX),fast = 10, slow = 20, signal = 5)#Calculate a MACD with standard parameters
MACDsignal<-MACD[,2]#Grab just the signal line to use as our indicator.
SMI<-SMI(Op(NDX),n=9,slow=15,fast=2,signal=5) #Stochastic Oscillator with standard parameters
SMI<-SMI[,1]#Grab just the oscillator to use as our indicator
**self indicator1
par(mfrow=c(2,2))
atrVOL<-na.omit(ATR(NDX[,2:4])[,2])
atrMA<-SMA(atrVOL,n=5)
SMA15<-SMA(Cl(NDX),n=15)
SMA50<-SMA(Cl(NDX),n=50)
roc1<-ROC(Cl(NDX),n=1,type="discrete")
roc5<-ROC(Cl(NDX),n=5,type="discrete")
roc10<-ROC(Cl(NDX),n=10,type="discrete")
roc15<-ROC(Cl(NDX),n=15,type="discrete")
wave<-roc1*0.5+(roc5*0.3+roc10*0.3+roc15*15)*0.5
atr<-atrVOL-atrMA
S15<-Op(NDX)-SMA15
S50<-Op(NDX)-SMA50
  *plot
plot(tail(wave,50))
plot(tail(atr,50))
plot(tail(S50,50))
plot(tail(S15,50))
plot(tail(RSI5,50))
plot(tail(EMAcross,50))
plot(tail(Trend,50))
plot(tail(MACDsignal,50))
plot(tail(SMI,50))
##F5****** Rolling Correlation
y1<-TD$USD_CAD
y2<-TD$TQQQ_SQQQ
y<-merge(y1,y2)
rolling_correlation<-rollapply(y,width=50,FUN=function(y) cor(y[,1],y[,2]),by.column = FALSE, align = "right")
plot(rolling_correlation)
##F5****Rolling Regression
rr <- rollapply(y, width = 36,FUN = function(y) coef(lm(y ~ y[,1] + y[,2], data = as.data.frame(y))),by.column = FALSE, align = "right")
plot(rr)
##F5# VOlume and price relation
par(mfrow=c(3,1))
PriceChange<- (log(Cl(NDX)) - log(Op(NDX)))
par(mfrow=c(3,1))
y1<-PriceChange
y2<-ROC(NDX[,4])
y<-merge(y1,y2)
rolling_correlation<-rollapply(y,width=50,FUN=function(y) cor(y[,1],y[,2]),by.column = FALSE, align = "right")
plot(rolling_correlation["2015/2016"])
rr <- rollapply(y, width = 36,FUN = function(y) coef(lm(y[,2] ~ y[,1], data = as.data.frame(y))),by.column = FALSE, align = "right")
plot(rr[,1])
plot(rr[,2])
##F5****CYCLE
#??lubridate
DayofWeek<-wday(TD, label=TRUE)
TD1<-data.frame(DayofWeek,TD)
table(TD1$DayofWeek,TD$PL)
table(TD1$DayofWeek,TD$VL)
TDm<-month(TD, label = TRUE)
TD2<-data.frame(TDm,TD)
table(TD2$TDm,TD2$PL)
table(TD2$TDm,TD2$VL)
TDm15<-month(TD["2015"], label = TRUE)
TD15<-data.frame(TDm15,TD["2015"])
table(TD15$TDm15,TD15$PL)
table(TD15$TDm15,TD15$VL)
##F4####HMM
LogReturns <- log(Cl(NDX)) - log(Op(NDX)) #calculate the logarithmic returns
dataHMM<-na.omit(data.frame(tail(LogReturns,1000),tail(***,1000)))
colnames(dataHMM)<-c("LogReturns","***") #name our columns 
set.seed(1)
HMM<-depmix(list(LogReturns~1,***~1),data=dataHMM,nstates=4,family=list(gaussian(),gaussian())) 
HMMfit<-fit(HMM, verbose = FALSE)
print(HMMfit)
summary(HMMfit) 
HMMpost<-posterior(HMMfit)
head(HMMpost)
par(mfrow=c(3,1))
plot(HMMpost$state)
plot(tail(***,50))
plot(tail(Cl(NDX),50))

##vGK#good to check
##TQQQ/SQQQ ratio   #Not significant 
##NDX/GSPC ratio   #Not significant
##TltEem ratio  #Not significant
##wave==good to check
##atr== good to check
##EMAcross== good to check
##SMI== not significant
##trend==not significant
##RSI3==good to check
##stochOsc==good to check
###svm CLASSIFICATION
****
PriceChange<- Cl(NDX) - Op(NDX)
Class<-ifelse(PriceChange>0,"UP","DOWN")
**
dataSVM<-data.frame(tail(Class,2000),tail(***,2000),tail(***,2000))
colnames(dataSVM)<-c("Class","***","***")
dataSVM<-na.omit(dataSVM)
set.seed(886)
split<-sample.split(dataSVM$Class, SplitRatio = 0.75)
trainSVM<-subset(dataSVM, split == TRUE)
testSVM<-subset(dataSVM, split == FALSE)
SVM<-svm(Class~***+***,data=trainSVM, kernel="radial",cost=1,gamma=1/2)
#Build our support vector machine using a radial basis function as our kernel, the cost, or C, at 1, and the gamma function at &frac12;, or 1 over the number of inputs we are using
TrainingPredictions<-predict(SVM,testSVM,type="class")
#Run the algorithm once more over the training set to visualize the patterns it found
TestData<-data.frame(testSVM,TrainingPredictions)#Create a data set with the predictions
ggplot(testSVM,aes(x=***,y=***))+stat_density2d(geom="contour",aes(color=TrainingPredictions))+labs(title="SVM *** and *** Predictions",x="***",y="***",color="Training Predictions")
**
plot(tail(***,50))

##F4#REGRESSION PREDICTION
logNDX<- log(Cl(NDX))-log(Op(NDX))
acf(na.omit(logNDX), lag.max=20) #16
pacf(na.omit(logNDX), lag.max=20)#16 
##ARIMA
NDXarima <- arima(logNDX, order=c(2,0,2)) # fit an ARIMA(p,d,q) model
NDXarimaforecasts <- forecast.Arima(NDXarima, h=1)
NDXarimaforecasts 

acf(NDXarimaforecasts $residuals, lag.max=20)
Box.test(NDXarimaforecasts $residuals, lag=20, type="Ljung-Box")
##GARCH
garchfit<-garchFit(~ garch(2,2), data =NDXdiff, trace = FALSE)
predict(garchfit, n.ahead = 1, plot=TRUE, crit_val=2)
##SVM
##source("e1071.R")#https://gist.github.com/ivannp/4180399  #copy and let run otherwise
tt<-get( getSymbols( "^NDX") )
rets<-na.trim((log(Cl(tt))-log(Op(tt))), type="discrete" )
# only the first two features so that we may see some results in reasonable time
dataSVM<-svmFeatures( tt )[,c(1,2)]
#data <- na.exclude(merge(rets,dataSVM))
rets<- rets[index(dataSVM)]
data<-dataSVM[index(rets)]
stopifnot( NROW( rets ) == NROW( data ) )
forecastSVM<-svmComputeForecasts(
    data=data,
    history=100,
    response=rets,
    cores=8,#for wondow =1
    trace=T,
    modelPeriod="days",
    startDate="2014-12-15",
    endDate="2016-01-07",
    featureSelection="all" ) ##for UBUNTU cores=8
    ts(last(forecastSVM)$Forecasts)[1]*ts(last(Cl(GSPC)))[1]## predicted value by SVM regression
####dataSET###
TD<-ROC(Cl(NDX))
TD$CH<-ifelse((log(Cl(NDX))-log(Op(NDX)))>0,1,0)# NDX
TD$NDX.Close<-NULL
TD$NDX<-(log(Cl(NDX))-log(Op(NDX)))
TD$GSPC<-(log(Cl(GSPC))-log(Op(GSPC)))
TD$OEX<-(log(Cl(OEX))-log(Op(OEX)))
TD$NDX_OEX<-Cl(NDX)/Cl(OEX)
TD$NDX_GSPC<-Cl(NDX)/Cl(GSPC)
TD$OEX_GSPC<-Cl(OEX)/Cl(GSPC)
TD$TQQQ_SQQQ<-Cl(TQQQ)/Cl(SQQQ)
TD$USD_CAD<-(log(Cl(`CAD=X`))-log(Op(`CAD=X`)))
TD$TLT_EEM<-Cl(TLT)/Cl(EEM)
TD$XLE<-(log(Cl(XLE))-log(Op(XLE)))
TD$XLF<-(log(Cl(XLF))-log(Op(XLF)))
TD$XLV<-(log(Cl(XLV))-log(Op(XLV)))
TD$XLY<-(log(Cl(XLY))-log(Op(XLY)))
TD$XLI<-(log(Cl(XLI))-log(Op(XLI)))
TD$DWTI<-(log(Cl(DWTI))-log(Op(DWTI)))
TD$USDCAD<-(log(Cl(`CAD=X`))-log(Op(`CAD=X`)))
TD$PCUD<-PCUD
TD$VCUD<-VCUD
TD$PL<-PL
TD$VL<-VL
TD$vGK<-vGK
TD$rollSD<-rollSD
TD$stochOsc<-stochOsc
TD$stochWPR<-stochWPR 
TD$RSI5<-RSI5
TD$EMAcross<-EMAcross
TD$Trend<-Trend
TD$MACDsignal<-MACDsignal
TD$SMI<-SMI
TD$wave<-wave
TD$atr<-atr
TD$P<-Cl(NDX)
*Train and Test set
set.seed(1000)
split<-sample.split(TD$CH,SplitRatio = 0.75)
train<-subset(TD,split=TRUE)
test<-subset(TD,split=FALSE)    
****correlation search
M<-cor(tail(TD,5))
diag(M)<-0    
M<-na.omit(M)
##F4#Regression prediction
glmNDX<-glm(CH ~OEX+DWTI+USDCAD+XLF+XLV+XLY+PL+VCUD,data=train,family=binomial)
#plot(glmNDX)
#exp(coef(glmNDX))
predictedNDXglm<-predict(glmNDX,test,type = "response")
plot(tail(predictedNDXglm,5))
last(predict(lm(formula = NDX ~ GSPC+XLE + XLF + XLV + XLY+XLI+VL+VCUD, data =train),test))
#F3:TREE
DecisionTree<-rpart(CH~PL+VL+PCUD+VCUD+Trend+EMAcross+RSI5+MACDsignal+SMI+wave+atr,data=TD, cp=.003)
prp(DecisionTree, type=2)
tail(TD)
DecisionTree<-rpart(CH~PL+Trend+EMAcross+RSI5+MACDsignal+SMI+wave+atr,data=TD, cp=.008)
prp(DecisionTree, type=2)
******
***MODEL NDX
NDX_logit<-glm(CH ~ OEX+XLF+XLV+XLB+XLY+XLI,data=TD,family=binomial)#y1
lmOEX<-lm(formula = OEX_R ~ NDX_R +FTSE_R+HSI_R+XLE_R + XLF_R + XLV_R + XLI_R, data =TD)#y2
lmNDX<-lm(formula = NDX_R ~ OEX_R +XLE_R + XLF_R +TQQQ_SQQQ, data = TD)#y3
fitOEX<-garchFit(~ garch(1, 1), data =TD$OEX_R, trace = FALSE, cond.dist="QMLE")
pOEX<-predict(fitOEX, n.ahead = 1)
fitNDX<-garchFit(~ garch(1, 1), data = TD$NDX_R, trace = FALSE, cond.dist="QMLE")
pNDX<-predict(fitNDX, n.ahead = 1)
fitFTSE<-garchFit(~ garch(1, 1), data =TD$FTSE_R, trace = FALSE, cond.dist="QMLE")
fitNDX<-garchFit(~ garch(1, 1), data = TD$NDX_R, trace = FALSE, cond.dist="QMLE")
pNDX<-predict(fitNDX, n.ahead = 1)
pFTSE<-predict(fitFTSE, n.ahead = 1)
fitHSI<-garchFit(~ garch(1, 1), data =TD$HSI_R, trace = FALSE, cond.dist="QMLE")
pHSI<-predict(fitHSI, n.ahead = 1)
fitXLE<-garchFit(~ garch(1, 1), data = TD$XLE_R, trace = FALSE, cond.dist="QMLE")
pXLE<-predict(fitXLE, n.ahead = 1)
fitXLF<-garchFit(~ garch(1, 1), data = TD$XLF_R, trace = FALSE, cond.dist="QMLE")
pXLF<-predict(fitXLF, n.ahead = 1)
fitXLV<-garchFit(~ garch(1, 1), data = TD$XLV_R, trace = FALSE, cond.dist="QMLE")
pXLV<-predict(fitXLV, n.ahead = 1)
fitXLI<-garchFit(~ garch(1, 1), data = TD$XLI_R, trace = FALSE, cond.dist="QMLE")
pXLI<-predict(fitXLI, n.ahead = 1)
fitXLB<-garchFit(~ garch(1, 1), data =TD$XLB_R, trace = FALSE, cond.dist="QMLE")
pXLB<-predict(fitXLB, n.ahead = 1)
fitXLY<-garchFit(~ garch(1, 1), data =TD$XLY_R, trace = FALSE, cond.dist="QMLE")
pXLY<-predict(fitXLY, n.ahead = 1)
fitTQQQ_SQQQ<-garchFit(~ garch(1, 1), data =TD$TQQQ_SQQQ, trace = FALSE, cond.dist="QMLE")
pTQQQ_SQQQ<-predict(fitTQQQ_SQQQ, n.ahead = 1)
#pNDX$meanForecast
fOEX<-sum(lmOEX$coefficients[2]*(pNDX$meanForecast)+lmOEX$coefficients[3]*(pFTSE$meanForecast)-lmOEX$coefficients[4]*(pHSI$meanForecast)+lmOEX$coefficients[5]*(pXLE$meanForecast)+lmOEX$coefficients[6]*(pXLF$meanForecast)+lmOEX$coefficients[7]*(pXLV$meanForecast)+lmOEX$coefficients[8]*(pXLI$meanForecast))
fNDX<-sum(lmNDX$coefficients[2]*(pOEX$meanForecast)+lmNDX$coefficients[3]*(pXLE$meanForecast)+lmNDX$coefficients[4]*(pXLF$meanForecast)+lmNDX$coefficients[5]*(pTQQQ_SQQQ$meanForecast))
chOEX<-ifelse(fOEX>0,1,0)
chFTSE<-ifelse(pFTSE>0,1,0)
chHSI<-ifelse(pHSI>0,1,0)
chXLE<-ifelse(pXLE>0,1,0)
chXLV<-ifelse(pXLV>0,1,0)
chXLF<-ifelse(pXLF>0,1,0)
chXLI<-ifelse(pXLI>0,1,0)
chXLB<-ifelse(pXLF>0,1,0)
chXLY<-ifelse(pXLI>0,1,0)
y1e<-exp(coef(NDX_logit))[1]+exp(coef(NDX_logit))[2]*chOEX+exp(coef(NDX_logit))[3]*chXLF+exp(coef(NDX_logit))[4]*chXLV+exp(coef(NDX_logit))[5]*chXLB+exp(coef(NDX_logit))[6]*chXLY+exp(coef(NDX_logit))[7]*chXLI
PE<-first(y1e/(1+y1e))[1]*100#probablity of UP/DOWN OF sp500
y1<-exp(coef(NDX_logit))[1]+exp(coef(NDX_logit))[2]*last(TD$OEX)[1]+exp(coef(NDX_logit))[3]*last(TD$XLF)[1]+exp(coef(NDX_logit))[4]*last(TD$XLV)[1]+exp(coef(NDX_logit))[5]*last(TD$XLB)[1]+exp(coef(NDX_logit))[6]*last(TD$XLY)[1]+exp(coef(NDX_logit))[7]*last(TD$XLI)[1]
P<-first(y1/(1+y1))[1]*100#probablity of UP/DOWN OF sp500
*RESULT
PE
P
ts((1+fOEX)*last(OEX$OEX.Close))[1]# forcasted OEX 
ts((1+fNDX)*last(NDX$NDX.Close))[1]# forcasted NDX 
***
NDX_R<-(Cl(NDX)/Op(NDX))-1# NDX
OIL_R<-(Cl(OIL)/Op(OIL))-1#OIL return
dataSVM<-data.frame(NDX_R,OIL_R)
colnames(dataSVM)<-c("CH","OIL")
dataSVM<-na.omit(dataSVM)
set.seed(886)
split<-sample.split(dataSVM$CH, SplitRatio = 0.75)
trainSVM<-subset(dataSVM, split == TRUE)
testSVM<-subset(dataSVM, split == FALSE)
***
model<-svm(CH~OIL,dataSVM)
predictedY <- predict(model, dataSVM)
last(predictedY)
**
tuneResult <- tune(svm, CH ~ OIL,  data = dataSVM,ranges = list(epsilon = seq(0.94,1,0.01), cost = 1.2^(2:4))) 
print(tuneResult)
plot(tuneResult)
***
tunedModel <- tuneResult$best.model
tunedModelY <- predict(tunedModel, dataSVM) 
***
mysvm_lin<-svm (TD$NDX_R,TD$CH, type='C', kernel='linear')
predsvm_lin<-predict (mysvm_lin,TD$NDX_R)
table(predsvm_lin,TD$CH)
#
mysvm_pol<-svm (TD$NDX_R,TD$CH, type='C', kernel='polynomial', degree=2)
predsvm_pol<-predict (mysvm_pol,TD$NDX_R)
table(predsvm_pol,TD$CH)
#
mysvm_gam<-svm (train$NDX_R,train$CH, type='C', kernel='radial', gamma=0.1)
predsvm_gam<-predict (mysvm_gam,test$NDX_R)
table(predsvm_gam,test$CH)

******Naive Bayes
#DayofWeek<-wday(NDX, label=TRUE) #not effctive
D_NB<-ifelse(ROC(Cl(GSPC))<=(-0.01),4,ifelse(ROC(Cl(GSPC))<=(-0.0075) & ROC(Cl(GSPC))>(-0.01),3,ifelse(ROC(Cl(GSPC))<=(-0.004) & ROC(Cl(GSPC))>(-0.0075),2,ifelse(ROC(Cl(GSPC))<=(-0.002) & ROC(Cl(GSPC))>(-0.004),1,0))))
PriceChange<- Cl(GSPC) - Op(GSPC)
Class<-ifelse(PriceChange>0,"UP","DOWN")
indicator<-round(RSI(Op(GSPC), n= 13))# indicator to add here
DataSetNB<-data.frame(D_NB,indicator, Class)#SI$U effective but L is not
DataSetNB<-na.omit(DataSetNB)
set.seed(88)
split<-sample.split(DataSetNB[,3], SplitRatio = 0.75)
TrainingSetNB<-subset(DataSetNB, split == TRUE)
TestSetNB<-subset(DataSetNB, split == FALSE)
NBModel<-naiveBayes(TrainingSetNB[,1:2],TrainingSetNB[,3])
table(predict(NBModel,TestSetNB),TestSetNB[,3],dnn=list('predicted','actual'))
#other indicators
EMA5<-EMA(Op(NDX),n = 5) 
EMA10<-EMA(Op(NDX),n = 10)
EMACross <- EMA5 - EMA10
indicator<-round(EMACross,2)

last(rollapply(as.xts(NDX[,4]),width=50,FUN="quantile",0.90,na.rm=TRUE))# quantile check of NDX above 90% 

*
last(rollapply(as.xts(Cl(NDX)),width=50,FUN="quantile",0.90,na.rm=TRUE))# quantile check of NDX above 90% 


***
DIRECTION OF INDEX MOVEMENT PREDICTION USING MACHINE LEARNING
Introduction
The basic form of effcient market hypothesis postulates that publicly available information is incorporated into stock prices.
The stronger form of the hypothesis asserts that all information are immediately reflected in the market as soon as they become 
available; whereas the weaker form allows a certain lag period in which the information is digested by the public and stock prices move
gradually towards the effcient target.
stock  price  series  are  generally quite noisy,dynamic,nonlinear,complicated,nonparametric, and chaotic by nature[1-4]. The noisy 
characteristic  refers  to  the  unavailability  of  complete information   from   the   past   behavior   of   financial markets  to 
fully  capture  the  dependency  between future and past prices[5-9].
Investors  could  effectively hedge against potential market risk and speculators as well   as   arbitrageurs   could   have  
opportunity   of making  profit  by  trading  stock  index  whenever  they could  obtain  the  accurate  prediction  of  stock  price 
direction.  That  is  why  there  have  been  a  number  of studies  looking  at  direction  or  trend  of  movement  of various kinds
of financial instruments [10-14]. 
Because  of  the  high  nonlinearity  of  the  stock market,  it  is  difficult  to  reveal  the  inside  law  by  the traditional
forecast  methods
[18]. The  difficulty  of prediction   lies   in   the   complexities   of   modeling human  behavior  [19]. In  response  to  such 
difficulty, data mining  (or  machine  learning)  techniques  have been   introduced   and   applied   for   this  
financial prediction.   Recent   studies   reveal  that   nonlinear models are able to simulate the volatile stock markets well and 
produce   better   predictive   results   than traditional  linear models  in  stock  market  tendency exploration[20].  With  the
development  of  artificial intelligence (AI) techniques investors are hoping that the market  mysteries can be  unraveled because
these methods  have  great  capability  in  pattern  recognition problems such as classification andprediction.
Many factors:(political  events,economic events,stock specific events,sector specific events,traders expectations,technical analysis 
output,machine learning output)
Several methods have been proposed for making prediction on stock market and devising profit-generating trading strategies:
Software
http://nlp.stanford.edu/software/lex-parser.shtml
http://nlp.stanford.edu/software/classifier.shtml
http://nlp.stanford.edu/software/tagger.shtml
Reference
http://nlp.stanford.edu/
http://nlp.stanford.edu/courses/
http://nlp.stanford.edu/courses/cs224n/2008/reports/21.pdf
http://nlp.stanford.edu/pubs/lrecstanforddeps_final_final.pdf
http://www.ijera.com/papers/Vol4_issue6/Version%202/Q04602106117.pdf
****
****
VIX mean chart
VIX tango
VIX-VIX put strategy
VIX,XIV,VXX,UVXX
*****
*****
1. Market Open up/down{premarket index,NQ future up/down,Asian Market reaction}
2. Market close is not dependent to 1
3. Market close { model,economic event on that day,news}
4. NDX has low correlation with other indices but needed for SQQQ,TQQQ
5. JUMP up/down 1% to 1.5% is important
6. UUUU,DDDD,UUUUU,DDDDD,UUUUUU,DDDDDD are important
7. lag1 is significant
******
****CORRELATION
GSPC:NDX,OEX,RUI,IXIC,SML,VIX
NDX:GSPC,OEX,RUI,IXIC,SPY
VIX:GSPC,OEX,VXN 
##Down above 0.2% leads 99% chance of down to next day
#DecisionTree<-rpart(Class~L+D+EMAcross+MACDsignal+Stochastic,data=TrainingSet, cp=.0015)
#prp(DecisionTree,type=2,extra=8)
#table(predict(DecisionTree,TestSet,type="class"),TestSet[,5],dnn=list('predicted','actual'))
***
Change of EEM
finance sector
health care sector
industries
USDCAD inversely
Trend and SMI inverse to USDCAD
4338,high probablity of UP
Technicals are not strong to UP direction but none has negative signal
premarket up
FUTURE UP
Emerging market positive
****
***CORRELATION
# correlation based reduction of variables
inTrain<-createDataPartition(y=TD$NDX,p=0.75,list=FALSE)
training<-TD[inTrain,]
testing<-TD[inTrain,]
M<-abs(cor(training[,-58])
diag(M)<-0
which(M>0.6,arr.ind=T)
#only cor(TD) is effective
*****LOGIT
set.seed(1000)
split<-sample.split(ind$CH,SplitRatio = 0.7)
train<-subset(ind,split=TRUE)
test<-subset(ind,split=FALSE)
ind_logit<-glm(CH ~.,data=train,family=binomial)
summary(ind_logit)
logit(p)= -5.5612+3.1135(OEX)+1.1719(NDX)-0.6868(VIX)+1.1870(XLE)+1.14685(XLF)+0.841(XLV)+1.0599(XLB)+1.343(XLY)+0.9275(XLI)
odd ratio=exp(logit(p))=20.5(OEX)+3.4(NDX)+0.51(VIX)+3.25(XLE)+4.53(XLF)+1.52(XLP)+2.12(XLV)+2.9(XLB)+3.65(XLY)+2.5(XLI)
#input of each element from "ind" datset
#exp(coef(ind_logit))  and exp(cbind(OR = coef(ind_logit), confint(ind_logit))) to get odd ratio
#p=probablity=exp(logit(p))/1+exp(logit(p))=odd ratio/1+odd ratio
#Model has 98% UP probablity if all are up
***MLR
plot(TDRdf$NDX,TDRdf$OEX)
lmOEX<-lm(formula = OEX ~ NDX +FTSE+HSI+XLE + XLF + XLV + XLI, data = TDRdf)#MLR model to predict OEX next day for logit model
***TREE
qplot(RSI3,ROC,color=Class,data=DataSet)
quantile(DataSet$RSI3)
set.seed(88)
split<-sample.split(DataSet$Class, SplitRatio = 0.75)
split
# Create training and testing sets
TrainingSet<-subset(DataSet, split == TRUE)
TestSet<-subset(DataSet, split == FALSE)
#TrainingSet<-DataSet[1:312,]#Use 2/3 of the data to build the tree
#TestSet<-DataSet[313:469,]#And leave out 1/3 data to test our strategy
DecisionTree<-rpart(Class~RSI3+EMAcross+MACDsignal+Stochastic,data=TrainingSet, cp=.001)
#Specifying the indicators to we want to use to predict the class and controlling the growth of the tree by setting the minimum amount of information gained (cp) needed to justify a split.
prp(DecisionTree,type=2,extra=8)
#Nice plotting tool with a couple parameters to make it look good. If you want to play around with the visualization yourself, here is a great resource.
printcp(DecisionTree)#PRUNE
#shows the minimal cp for each trees of each size.
plotcp(DecisionTree,upper="splits")
#plots the average geometric mean for trees of each size.
PrunedDecisionTree<-prune(DecisionTree,cp=0.0272109)
#I am selecting the complexity parameter (cp) that has the lowest cross-validated error (xerror)
prp(PrunedDecisionTree, type=2, extra=8)
table(predict(PrunedDecisionTree,TestSet,type="class"),TestSet[,5],dnn=list('predicted','actual'))

##DecisionTree<-rpart(Class~L+U+RSI3,data=TrainingSet, cp=.001)
##DecisionTree<-rpart(Class~L+RSI3+EMAcross,data=TrainingSet, cp=.0083)
##DecisionTree<-rpart(Class~L+D+RSI3+EMAcross+MACDsignal+Stochastic,data=TrainingSet, cp=.0005)
## DataSet$S1<-ifelse(DataSet$L==4 & DataSet$Stochastic<62,1,0) # top quartile and stochastic below 62 ==UP
DecisionTree<-rpart(Class~L+U+Stochastic,data=TrainingSet, cp=.0015)#<52
DecisionTree<-rpart(Class~L+MACDsignal,data=TrainingSet, cp=.0035)
DecisionTree<-rpart(Class~L+EMAcross,data=TrainingSet, cp=.005)
DecisionTree<-rpart(Class~L+RSI3,data=TrainingSet, cp=.005)
prp(DecisionTree, type=2, extra=8)
https://inovancetech.com/blogML3.html
**Other Packages
library("evtree", lib.loc="~/R/win-library/3.2")
DTev<-evtree(Class~RSI3+EMAcross+MACDsignal+Stochastic,data=TrainingSet)
plot(DTev)
table(predict(DTev), TrainingSet$Class)
1-mean(predict(DTev) ==TrainingSet$Class)
library("maptree", lib.loc="~/R/win-library/3.2")
library("cluster", lib.loc="C:/Program Files/R/R-3.2.1/library")
draw.tree( clip.rpart (rpart (TrainingSet), best=7),nodeinfo=TRUE, units="species",cases="cells", digits=0)
library("party", lib.loc="~/R/win-library/3.2")
(ct = ctree(Class~RSI3+EMAcross+MACDsignal+Stochastic,data=TrainingSet))
plot(ct, main="Conditional Inference Tree")
#Table of prediction errors
table(predict(ct), TrainingSet$Class)
# Estimated class probabilities
tr.pred<-predict(ct, newdata=TestSet, type="prob")
library("tree", lib.loc="~/R/win-library/3.2")
tr<-tree(Class~RSI3+EMAcross+MACDsignal+Stochastic,data=TrainingSet)
summary(tr)
plot(tr)
text(tr)
***BAGGING
library("mlbench", lib.loc="~/R/win-library/3.2")
library("adabag", lib.loc="~/R/win-library/3.2")
BAgging<-bagging(Class~RSI3+EMAcross+MACDsignal+Stochastic,data=TrainingSet)
BAgging.pred<-predict.bagging(BAgging,newdata=TestSet)
BAgging.pred$error
BAgging.pred$confusion
****RandomFOrest
library("randomForest", lib.loc="~/R/win-library/3.2")
RF<-randomForest(Class~L+U+RSI3+EMAcross+MACDsignal+Stochastic,data=DataSet)
RF<-randomForest(Class~L+D+RSI3+EMAcross+MACDsignal+Stochastic,data=DataSet)
print(RF)
importance(RF)
plot(RF)
plot( importance(RF), lty=2, pch=16)
lines(importance(RF))
**
library("CORElearn", lib.loc="~/R/win-library/3.2")
## Random Forests
RMcoremodel<-CoreModel(Class~RSI3+EMAcross+MACDsignal+Stochastic,data=TrainingSet, model="rf", selectionEstimator="MDL", minNodeWeightRF=5, rfNoTrees=20)
plot(RMcoremodel)
## decision tree with naive Bayes in the leaves
RMcoremodelNB<-CoreModel(Class~RSI3+EMAcross+MACDsignal+Stochastic,data=TrainingSet, model="tree", modelType=4)
plot(RMcoremodelNB,TrainingSet)
RMcoremodelRT<-CoreModel(Class~RSI3+EMAcross+MACDsignal+Stochastic,data=TrainingSet, model="regTree", modelTypeReg=1) 
summary(RMcoremodelRT)
plot(RMcoremodelRT,TestSet, graphType="prototypes")
pred<-predict(RMcoremodelRT,TestSet)
print(pred)
plot(pred)
******Naive Bayes
#DayofWeek<-wday(NDX, label=TRUE) #not effctive
PriceChange<- Cl(NDX) - Op(NDX)
Class<-ifelse(PriceChange>0,"UP","DOWN")
indicator<-round(RSI(Op(NDX), n= 13))# indicator to add here
DataSetNB<-data.frame(SI$D,indicator, Class)#SI$U effective but L is not
DataSetNB<-na.omit(DataSetNB)
set.seed(88)
split<-sample.split(DataSetNB[,3], SplitRatio = 0.75)
TrainingSet<-subset(DataSetNB, split == TRUE)
TestSet<-subset(DataSetNB, split == FALSE)
NBModel<-naiveBayes(TrainingSet[,1:2],TrainingSet[,3])
table(predict(NBModel,TestSet),TestSet[,3],dnn=list('predicted','actual'))
#other indicators
EMA5<-EMA(Op(NDX),n = 5) 
EMA10<-EMA(Op(NDX),n = 10)
EMACross <- EMA5 - EMA10
indicator<-round(EMACross,2)

USD.CAD
TQQQ/SQQQ
TLT-NDX
****
PriceChange<- Cl(GSPC) - Op(GSPC)
Class<-ifelse(PriceChange>0,"UP","DOWN")
RSI<-round(RSI(Op(GSPC), n= 13))# indicator to add here
EMA5<-EMA(Op(GSPC),n=5)
#Calculate a 5-period exponential moving average (EMA)
EMAcross<- Op(GSPC)-EMA5
SMA50<-SMA(Op(GSPC),n=50)
Trend<-Op(GSPC)-SMA50#Our measure of trend: the difference between the open price and the 50-period simple moving average.
MACD<-MACD(Op(GSPC),fast = 12, slow = 26, signal = 9)
#Calculate a MACD with standard parameters
MACDsignal<-MACD[,2]
#Grab just the signal line to use as our indicator.
SMI<-SMI(Op(GSPC),n=13,slow=25,fast=2,signal=9) 
#Stochastic Oscillator with standard parameters
SMI<-SMI[,1]
U<-ifelse(ROC(Cl(GSPC))>=0.01,4,ifelse(ROC(Cl(GSPC))>=0.0075 & ROC(Cl(GSPC))<0.01,3,ifelse(ROC(Cl(GSPC))>=0.004 & ROC(Cl(GSPC))<0.0075,2,ifelse(ROC(Cl(GSPC))>=0.002 & ROC(Cl(GSPC))<0.004,1,0))))
D<-ifelse(ROC(Cl(GSPC))<=(-0.01),4,ifelse(ROC(Cl(GSPC))<=(-0.0075) & ROC(Cl(GSPC))>(-0.01),3,ifelse(ROC(Cl(GSPC))<=(-0.004) & ROC(Cl(GSPC))>(-0.0075),2,ifelse(ROC(Cl(GSPC))<=(-0.002) & ROC(Cl(GSPC))>(-0.004),1,0))))
dataSVM<-data.frame(Class,Trend,EMAcross)
colnames(dataSVM)<-c("Class","Trend","EMAcross")
dataSVM<-na.omit(dataSVM)
set.seed(886)
split<-sample.split(dataSVM$Class, SplitRatio = 0.75)
trainSVM<-subset(dataSVM, split == TRUE)
testSVM<-subset(dataSVM, split == FALSE)
SVM<-svm(Class~Trend+EMAcross,data=trainSVM, kernel="radial",cost=1,gamma=1/2)
#Build our support vector machine using a radial basis function as our kernel, the cost, or C, at 1, and the gamma function at &frac12;, or 1 over the number of inputs we are using
TrainingPredictions<-predict(SVM,testSVM,type="class")
#Run the algorithm once more over the training set to visualize the patterns it found
TestData<-data.frame(testSVM,TrainingPredictions)#Create a data set with the predictions
ggplot(testSVM,aes(x=EMAcross,y=Trend))+stat_density2d(geom="contour",aes(color=TrainingPredictions))+labs(title="SVM Predictions",x="EMAcross",y="Trend",color="Training Predictions")
